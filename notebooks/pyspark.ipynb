{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3f8174e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import requests\n",
    "\n",
    "from datetime import datetime\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce88b589",
   "metadata": {},
   "source": [
    "# Pemrosesan Data Menggunakan Apache Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c60b9b",
   "metadata": {},
   "source": [
    "Percobaan kali ini secara proses hampir sama seperti yang dilakukan pada proses etl sebelumnya, namun satu yang berbeda adalah penggunaan *Apache Spark* untuk pemrosesan data. Yang mana sebelumnya hanya menggunakan dataframe dari pandas. Kekurangan dari penggunaan pandas adalah pada *Eager Execution* dimana ketika butuh proses transformasi yang berulang akan cukup merepotkan. Oleh karena itulah disini spark digunakan, dimana kita bisa menyusun tahapan-tahapan transformasi terlebih dahulu tanpa langsung melakukan transformasi secara eksplisit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182ec3b0",
   "metadata": {},
   "source": [
    "Ada yang berbeda juga kali ini dimana data sebelumnya ada di kota *San Fransisco*, untuk kali ini kami melakukan beberapa penyesuaian yaitu dengan merubah tempat menjadi *Kota Malang*. Adapun untuk sumber data yang kami gunakan masih tetap berasal dari API Open-meteo (https://open-meteo.com/en/docs/historical-weather-api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "834397b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tambahkan 2 baris ini agar spark mengenali env python\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fddfd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buat spark session terlebih dahulu\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"rdv-project\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db389eb8",
   "metadata": {},
   "source": [
    "# Extract Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf30719e",
   "metadata": {},
   "source": [
    "Ekstraksi data yang dilakukan juga akan berbeda dari tugas sebelumnya. Pada tugas sebelumnya hanya menggunakan satu fitur saja yaitu temperature_2m. Namun pada kali ini karena spark memanfaatkan memori untuk pemrosesan data, kami akan mengambil lebih banyak fitur."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ed1e2f",
   "metadata": {},
   "source": [
    "List fitur yang akan dipakai : \n",
    "- `temperature_2m`,\n",
    "- `relative_humidity_2m`,\n",
    "- `precipitation`,\n",
    "- `weather_code`,\n",
    "- `wind_speed_10m`,\n",
    "- `wind_speed_100m`,\n",
    "- `wind_direction_10m`,\n",
    "- `wind_direction_100m`,\n",
    "- `wind_gusts_10m`,\n",
    "- `rain`,\n",
    "- `apparent_temperature`,\n",
    "- `surface_pressure`,\n",
    "- `cloud_cover`,\n",
    "- `cloud_cover_low`,\n",
    "- `cloud_cover_mid`,\n",
    "- `cloud_cover_high`,\n",
    "- `soil_temperature_0_to_7cm`,\n",
    "- `soil_temperature_7_to_28cm`,\n",
    "- `soil_temperature_28_to_100cm`,\n",
    "- `soil_temperature_100_to_255cm`,\n",
    "- `soil_moisture_0_to_7cm`,\n",
    "- `soil_moisture_7_to_28cm`,\n",
    "- `soil_moisture_28_to_100cm`,\n",
    "- `soil_moisture_100_to_255cm`,\n",
    "- `et0_fao_evapotranspiration`,\n",
    "- `vapour_pressure_deficit`,\n",
    "- `pressure_msl`,\n",
    "- `dew_point_2m`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0c6710",
   "metadata": {},
   "source": [
    "Bisa dilihat bahwa fitur yang diambil bisa dibilang cukup banyak. Jika hanya untuk dashboard saja yang tujuannya untuk monitoring cuaca saat ini, fitur-fitur seperti informasi keadaan tanah dan lain-lain yang terlalu spesifik mungkin tidak diperlukan. Akan tetapi kebutuhan akan berbeda ketika ada pertimbangan untuk melakukan **prediksi** kode cuaca (*weather code*) dari semua fitur yang ada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35b51456",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Malang sendiri sebenarnya tidak memiliki stasiun pengukuran dari BMKG\n",
    "Oleh karena itu latitude dan longitude di bawah ini menunjukkan \n",
    "koordinat dari kota malang seluruhnya\n",
    "\"\"\"\n",
    "# --------------------------- Parameter API -------------------------\n",
    "\n",
    "# Latitude & Longitude utk Malang\n",
    "latitude = -7.96611694302791\n",
    "longitude = 112.62816916904798\n",
    "\n",
    "# Tanggal\n",
    "start_date = \"2024-01-01\"\n",
    "today = datetime.today()\n",
    "today_str = today.strftime(\"%Y-%m-%d\")\n",
    "end_date = today_str\n",
    "\n",
    "# List Fitur\n",
    "feature_list = [\n",
    "    \"temperature_2m\",\n",
    "    \"relative_humidity_2m\",\n",
    "    \"precipitation\",\n",
    "    \"weather_code\",\n",
    "    \"wind_speed_10m\",\n",
    "    \"wind_speed_100m\",\n",
    "    \"wind_direction_10m\",\n",
    "    \"wind_direction_100m\",\n",
    "    \"wind_gusts_10m\",\n",
    "    \"rain\",\n",
    "    \"apparent_temperature\",\n",
    "    \"surface_pressure\",\n",
    "    \"cloud_cover\",\n",
    "    \"cloud_cover_low\",\n",
    "    \"cloud_cover_mid\",\n",
    "    \"cloud_cover_high\",\n",
    "    \"soil_temperature_0_to_7cm\",\n",
    "    \"soil_temperature_7_to_28cm\",\n",
    "    \"soil_temperature_28_to_100cm\",\n",
    "    \"soil_temperature_100_to_255cm\",\n",
    "    \"soil_moisture_0_to_7cm\",\n",
    "    \"soil_moisture_7_to_28cm\",\n",
    "    \"soil_moisture_28_to_100cm\",\n",
    "    \"soil_moisture_100_to_255cm\",\n",
    "    \"et0_fao_evapotranspiration\",\n",
    "    \"vapour_pressure_deficit\",\n",
    "    \"pressure_msl\",\n",
    "    \"dew_point_2m\"\n",
    "]\n",
    "features = \",\".join(feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "15bc8ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting data for 2017\n",
      "Getting data for 2018\n",
      "Getting data for 2019\n",
      "Getting data for 2020\n",
      "Getting data for 2021\n",
      "Getting data for 2022\n",
      "Getting data for 2023\n",
      "Getting data for 2024\n",
      "Getting data for 2025\n"
     ]
    }
   ],
   "source": [
    "final_psdf = None\n",
    "\n",
    "for year in range(2017, 2025+1):\n",
    "    start_date = f\"{year}-01-01\"\n",
    "    end_date = f\"{year}-12-31\"\n",
    "    if year==2025:\n",
    "        end_date = f\"{year}-05-11\"\n",
    "\n",
    "    url = f\"https://archive-api.open-meteo.com/v1/archive?latitude={latitude}&longitude={longitude}&start_date={start_date}&end_date={end_date}&hourly={features}&timezone=auto\"\n",
    "\n",
    "    success = False\n",
    "    attempts = 0\n",
    "\n",
    "    while not success and attempts < 3:\n",
    "        try:\n",
    "            print(f\"Getting data for {year}\")\n",
    "            res = requests.get(url)\n",
    "            if res.status_code == 200:\n",
    "                data = res.json()\n",
    "                data = data['hourly']\n",
    "                psdf = spark.read.json(spark.sparkContext.parallelize(data))\n",
    "\n",
    "                if final_psdf is None:\n",
    "                    final_psdf = psdf\n",
    "                else :\n",
    "                    final_psdf = final_psdf.unionByName(psdf)\n",
    "                \n",
    "                success = True\n",
    "                time.sleep(60)\n",
    "            elif res.status_code == 429:\n",
    "                print(f\"Limit rate has been reached, retrying...\")\n",
    "                time.sleep(60)\n",
    "                attempts += 1\n",
    "                print(f\"#### Attempts : {attempts+1}/3 ####\")\n",
    "            elif res.status_code == 443:\n",
    "                print(f\"Error status code {res.status_code}, retrying...\")\n",
    "                time.sleep(60)\n",
    "                attempts += 1\n",
    "                print(f\"#### Attempts : {attempts+1}/3 ####\")\n",
    "            else :\n",
    "                print(f\"Failed to get data on {year}. status : {res.status_code}\")\n",
    "                break\n",
    "        except Exception as e:\n",
    "            print(f\"Error while get data on {year}, retrying...\")\n",
    "            time.sleep(60)\n",
    "            attempts += 1\n",
    "            print(f\"#### Attempts : {attempts+1}/3 ####\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "682366a3",
   "metadata": {},
   "source": [
    "# Transform Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d2d7558",
   "metadata": {},
   "source": [
    "## Structuring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1e8f4a",
   "metadata": {},
   "source": [
    "Tahap structuring sudah dilakukan bersamaan dengan ekstrak data dari API open-meteo. Adapun pada section structuring disini akan dilakukan pengecekan kolom pada data yang telah diambil sebelumnya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d540db67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|     _corrupt_record|\n",
      "+--------------------+\n",
      "|                time|\n",
      "|      temperature_2m|\n",
      "|relative_humidity_2m|\n",
      "|       precipitation|\n",
      "|        weather_code|\n",
      "|      wind_speed_10m|\n",
      "|     wind_speed_100m|\n",
      "|  wind_direction_10m|\n",
      "| wind_direction_100m|\n",
      "|      wind_gusts_10m|\n",
      "|                rain|\n",
      "|apparent_temperature|\n",
      "|    surface_pressure|\n",
      "|         cloud_cover|\n",
      "|     cloud_cover_low|\n",
      "|     cloud_cover_mid|\n",
      "|    cloud_cover_high|\n",
      "|soil_temperature_...|\n",
      "|soil_temperature_...|\n",
      "|soil_temperature_...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_psdf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a453f583",
   "metadata": {},
   "source": [
    "ternyata masih ada kesalahan dalam strukturisasi dataframe, dimana data masih tersusun selayaknya list dengan satu kolom saja."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de932f03",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e89442",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "363b2545",
   "metadata": {},
   "source": [
    "## Validating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49a036f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "02ae7241",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd1c976",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rdvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
