{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c26f67a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import requests\n",
    "import pycouchdb\n",
    "import hashlib\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('../src/kafka_etl/.env')\n",
    "\n",
    "from functools import reduce\n",
    "from datetime import datetime, timedelta, timezone\n",
    "import pytz\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b85d75a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "COUCHDB_UNAME = os.getenv(\"APP_USER\")\n",
    "COUCHDB_PWD = os.getenv(\"APP_PASSWORD\")\n",
    "COUCHDB_HOST = os.getenv(\"COUCHDB_HOST\", \"localhost\")\n",
    "COUCHDB_PORT = os.getenv(\"COUCHDB_PORT\", \"5984\")\n",
    "KAFKA_BOOTSTRAP_SERVERS = os.getenv(\"KAFKA_BOOTSTRAP_SERVERS\", \"localhost:29092\")\n",
    "\n",
    "# 5 second timeout\n",
    "KAFKA_CONSUMER_TIMEOUT_MS = int(os.getenv(\"KAFKA_CONSUMER_TIMEOUT_MS\", \"5000\"))\n",
    "\n",
    "THREAD_RESTART_DELAY_S = int(os.getenv(\"THREAD_RESTART_DELAY_S\", \"10\"))\n",
    "COUCHDB_URL = f\"http://{COUCHDB_UNAME}:{COUCHDB_PWD}@{COUCHDB_HOST}:{COUCHDB_PORT}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f672a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURE_LIST = [\n",
    "    'datetime',                     \n",
    "    'temperature_2m',              \n",
    "    'is_day',                        \n",
    "    'relative_humidity_2m',        \n",
    "    'dew_point_2m',                \n",
    "    'apparent_temperature',        \n",
    "    'precipitation',               \n",
    "    'weather_code',                \n",
    "    'pressure_msl',                \n",
    "    'surface_pressure',            \n",
    "    'cloud_cover',                 \n",
    "    'cloud_cover_low',             \n",
    "    'cloud_cover_mid',             \n",
    "    'cloud_cover_high',            \n",
    "    'et0_fao_evapotranspiration',  \n",
    "    'vapour_pressure_deficit',     \n",
    "    'wind_speed_10m',              \n",
    "    'wind_direction_10m',          \n",
    "    'wind_gusts_10m',              \n",
    "    'lat',\n",
    "    'lon',\n",
    "    'utc_offset_seconds',\n",
    "    'timezone',\n",
    "    'timezone_abbreviation',\n",
    "    'kab_kota'\n",
    "]\n",
    "\n",
    "FEATURES = \",\".join(FEATURE_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cec3d57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Use sc:// scheme for remote Spark Connect server\n",
    "spark = SparkSession.builder.remote(\"sc://localhost:15002\").getOrCreate()\n",
    "\n",
    "df = spark.createDataFrame([(14, \"Tom\"), (23, \"Alice\"), (16, \"Bob\")], [\"age\", \"name\"])\n",
    "print(df.count())\n",
    "\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd3ddca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SparkPP:\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2e8f8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rdvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
